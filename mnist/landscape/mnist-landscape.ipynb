{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72e9f236-9c15-4758-8b95-3b11658f28dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "\n",
    "def train(params):\n",
    "    data_size = int(params[0])\n",
    "    alpha = params[1]\n",
    "    \n",
    "    steps = 10000\n",
    "    \n",
    "    def cycle(iterable):\n",
    "        while True:\n",
    "            for x in iterable:\n",
    "                yield x\n",
    "            \n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    #train = torchvision.datasets.MNIST(root=\"/tmp\", train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "    #test = torchvision.datasets.MNIST(root=\"/tmp\", train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "    #train_loader = torch.utils.data.DataLoader(train, batch_size=50, shuffle=True)\n",
    "    \n",
    "    def accuracy(network, dataset, device, N=2000, batch_size=50):\n",
    "        dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for x, labels in islice(dataset_loader, N // batch_size):\n",
    "            logits = network(x.to(device))\n",
    "            predicted_labels = torch.argmax(logits, dim=1)\n",
    "            correct += torch.sum(predicted_labels == labels.to(device))\n",
    "            total += x.size(0)\n",
    "        return correct / total\n",
    "    \n",
    "    def loss_f(network, dataset, device, N=2000, batch_size=50):\n",
    "        dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        loss = 0\n",
    "        total = 0\n",
    "        for x, labels in islice(dataset_loader, N // batch_size):\n",
    "            logits = network(x.to(device))\n",
    "            loss += torch.sum((logits-torch.eye(10,)[labels])**2)\n",
    "            total += x.size(0)\n",
    "        return loss / total\n",
    "\n",
    "    train = torchvision.datasets.MNIST(root=\"/tmp\", train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "    test = torchvision.datasets.MNIST(root=\"/tmp\", train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "    data_size = data_size\n",
    "    train = torch.utils.data.Subset(train, range(data_size))\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=100, shuffle=True)\n",
    "    \n",
    "    def L2(model):\n",
    "        L2_ = 0.\n",
    "        for p in mlp.parameters():\n",
    "            L2_ += torch.sum(p**2)\n",
    "        return L2_\n",
    "\n",
    "    def rescale(model, alpha):\n",
    "        for p in mlp.parameters():\n",
    "            p.data = alpha * p.data\n",
    "            \n",
    "            \n",
    "    width = 200\n",
    "    mlp = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(28*28, width),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(width, width),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(width, 10)\n",
    "    ).to(device)\n",
    "\n",
    "    rescale(mlp, alpha)\n",
    "    L2_ = L2(mlp)\n",
    "    \n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(mlp.parameters(), lr=1e-3, weight_decay=0.0)\n",
    "    \n",
    "    one_hots = torch.eye(10, 10).to(device)\n",
    "    \n",
    "    mlp.eval()\n",
    "    print(\"Initial accuracy: {0:.4f}\".format(accuracy(mlp, test, device)))\n",
    "\n",
    "    test_accuracies = []\n",
    "    train_accuracies = []\n",
    "\n",
    "    i = 0\n",
    "    mlp.train()\n",
    "    pbar = tqdm(islice(cycle(train_loader), steps), total=steps)\n",
    "    \n",
    "    best_train_loss = 1e4\n",
    "    best_test_loss = 1e4\n",
    "    best_train_acc = 0.\n",
    "    best_test_acc = 0.\n",
    "    \n",
    "    for x, label in pbar:\n",
    "        mlp.train()\n",
    "        optimizer.zero_grad()\n",
    "        loss_train = loss_fn(mlp(x.to(device)), one_hots[label])\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        L2_new = L2(mlp)\n",
    "        # rescale weights such that the weight norm remains a constant in training.\n",
    "        rescale(mlp, torch.sqrt(L2_/L2_new))\n",
    "        if i % 50 == 0:\n",
    "            with torch.no_grad():\n",
    "                mlp.eval()\n",
    "                train_acc = accuracy(mlp, train, device).item()\n",
    "                test_acc = accuracy(mlp, test, device).item()\n",
    "                train_loss = loss_f(mlp, train, device).item()\n",
    "                test_loss = loss_f(mlp, test, device).item()\n",
    "                #train_accuracies.append(train_acc)\n",
    "                #test_accuracies.append(test_acc)\n",
    "                if train_acc > best_train_acc:\n",
    "                    best_train_acc = train_acc\n",
    "                if test_acc > best_test_acc:\n",
    "                    best_test_acc = test_acc\n",
    "                if train_loss < best_train_loss:\n",
    "                    best_train_loss = train_loss\n",
    "                if test_loss < best_test_loss:\n",
    "                    best_test_loss = test_loss\n",
    "                mlp.train()\n",
    "                pbar.set_description(\"{:3.3f} | {:3.3f} | {:3.3f} | {:3.3f}\".format(train_acc, test_acc, train_loss, test_loss))\n",
    "        i += 1\n",
    "    np.savetxt(\"./mnist_landscape/trainacc_%d_%.2f.txt\"%(data_size, alpha), np.array([best_train_acc]))\n",
    "    np.savetxt(\"./mnist_landscape/testacc_%d_%.2f.txt\"%(data_size, alpha), np.array([best_test_acc]))\n",
    "    np.savetxt(\"./mnist_landscape/trainloss_%d_%.2f.txt\"%(data_size, alpha), np.array([best_train_loss]))\n",
    "    np.savetxt(\"./mnist_landscape/testloss_%d_%.2f.txt\"%(data_size, alpha), np.array([best_test_loss]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51187f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_sizes = list([int(item) for item in 10**np.linspace(1,4,num=22)]) + list([int(item) for item in list(10**np.linspace(4,5,num=8)[1:6])+[60000]])\n",
    "\n",
    "alphas = 10**np.linspace(-1,1,num=21)\n",
    "\n",
    "\n",
    "xx, yy = np.meshgrid(data_sizes, alphas)\n",
    "params = list(np.transpose(np.array([xx.reshape(-1,), yy.reshape(-1,)])))\n",
    "\n",
    "from multiprocess import Pool\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(11) as p:\n",
    "        print(p.map(train, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b92069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
